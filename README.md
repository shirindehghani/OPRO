# OPRO (Optimization by PROmpting)

### Unofficial LangChain implemenation of Large Language Models as Optimizers:
![image](https://github.com/shirindehghani/OPRO/blob/main/src/images/abstract.png)

### TODO :
For using this code in your project, you should modify `configs.py` and also `extract_label()` function in `opro.py` file.

### Instalation :
`pip install -r requirements.txt`.

This project support Llama-3, GPT-4 and GPT-3.5 LLMs.

# Refrences
`@article{yang2023large,
  title={Large language models as optimizers},
  author={Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao and Le, Quoc V and Zhou, Denny and Chen, Xinyun},
  journal={arXiv preprint arXiv:2309.03409},
  year={2023}
}`
\\
[-Medium](https://medium.com/@minh.hoque/large-language-models-as-optimizers-explained-a20dc5e5c5af)
