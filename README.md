# OPRO (Large Language Models as Optimizers)
![image](https://img.shields.io/badge/-LangChain-32CD32?logo=LangChain&logoColor=white&style=for-the-badge)
![image](https://img.shields.io/badge/OpenAI-412991.svg?style=for-the-badge&logo=OpenAI&logoColor=white)
![image](https://www.searchenginejournal.com/wp-content/uploads/2023/04/hugging-face-huggingchat-644a286dee829-sej.png)
</br>

![image](https://github.com/shirindehghani/OPRO/blob/main/src/Assets/abstract.png)

### TODO :
For using this code in your project, you should modify `configs.py` and also `extract_label()` function in `opro.py` file.

### Instalation :
`pip install -r requirements.txt`.

This project support Llama-3, GPT-4 and GPT-3.5 LLMs. The default mode is Llama-3.

# Refrences
```
@article{yang2023large,
  title={Large language models as optimizers},
  author={Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao and Le, Quoc V and Zhou, Denny and Chen, Xinyun},
  journal={arXiv preprint arXiv:2309.03409},
  year={2023}
}
```
<br/>

[-Medium](https://medium.com/@minh.hoque/large-language-models-as-optimizers-explained-a20dc5e5c5af)

<br/>

[-GitHub](https://github.com/google-deepmind/opro)
